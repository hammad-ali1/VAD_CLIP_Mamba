{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/hammad-ali1/vad_clip_colab_notebook/blob/main/vad_clip_notebook.ipynb)\n"
      ],
      "metadata": {
        "id": "hjJEkZzImzOk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!pip install ftfy\n",
        "!pip install comet_ml\n",
        "!pip install torch==2.4.0 torchvision==0.19.0 torchaudio==2.4.0\n",
        "!pip install causal-conv1d==1.4.0 && pip install mamba-ssm==2.2.2\n",
        "!pip install fvcore"
      ],
      "metadata": {
        "id": "6DfMHfDVZPB8",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eb367ed8-a46c-4b05-fd62-984bae7ac849"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ftfy\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy) (0.2.13)\n",
            "Downloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ftfy\n",
            "Successfully installed ftfy-6.3.1\n",
            "Collecting comet_ml\n",
            "  Downloading comet_ml-3.51.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting dulwich!=0.20.33,>=0.20.6 (from comet_ml)\n",
            "  Downloading dulwich-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.2 kB)\n",
            "Collecting everett<3.2.0,>=1.0.1 (from everett[ini]<3.2.0,>=1.0.1->comet_ml)\n",
            "  Downloading everett-3.1.0-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: jsonschema!=3.1.0,>=2.6.0 in /usr/local/lib/python3.12/dist-packages (from comet_ml) (4.25.1)\n",
            "Requirement already satisfied: psutil>=5.6.3 in /usr/local/lib/python3.12/dist-packages (from comet_ml) (5.9.5)\n",
            "Collecting python-box<7.0.0 (from comet_ml)\n",
            "  Downloading python_box-6.1.0-py3-none-any.whl.metadata (7.8 kB)\n",
            "Requirement already satisfied: requests-toolbelt>=0.8.0 in /usr/local/lib/python3.12/dist-packages (from comet_ml) (1.0.0)\n",
            "Requirement already satisfied: requests>=2.18.4 in /usr/local/lib/python3.12/dist-packages (from comet_ml) (2.32.4)\n",
            "Requirement already satisfied: rich>=13.3.2 in /usr/local/lib/python3.12/dist-packages (from comet_ml) (13.9.4)\n",
            "Requirement already satisfied: semantic-version>=2.8.0 in /usr/local/lib/python3.12/dist-packages (from comet_ml) (2.10.0)\n",
            "Requirement already satisfied: sentry-sdk>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from comet_ml) (2.35.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from comet_ml) (75.2.0)\n",
            "Requirement already satisfied: simplejson in /usr/local/lib/python3.12/dist-packages (from comet_ml) (3.20.1)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from comet_ml) (2.5.0)\n",
            "Requirement already satisfied: wrapt>=1.11.2 in /usr/local/lib/python3.12/dist-packages (from comet_ml) (1.17.3)\n",
            "Requirement already satisfied: wurlitzer>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from comet_ml) (3.1.1)\n",
            "Collecting configobj (from everett[ini]<3.2.0,>=1.0.1->comet_ml)\n",
            "  Downloading configobj-5.0.9-py2.py3-none-any.whl.metadata (3.2 kB)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema!=3.1.0,>=2.6.0->comet_ml) (0.27.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.18.4->comet_ml) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.18.4->comet_ml) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.18.4->comet_ml) (2025.8.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.3.2->comet_ml) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=13.3.2->comet_ml) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=13.3.2->comet_ml) (0.1.2)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from referencing>=0.28.4->jsonschema!=3.1.0,>=2.6.0->comet_ml) (4.14.1)\n",
            "Downloading comet_ml-3.51.0-py3-none-any.whl (731 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.9/731.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dulwich-0.24.1-cp312-cp312-manylinux_2_28_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading everett-3.1.0-py2.py3-none-any.whl (35 kB)\n",
            "Downloading python_box-6.1.0-py3-none-any.whl (27 kB)\n",
            "Downloading configobj-5.0.9-py2.py3-none-any.whl (35 kB)\n",
            "Installing collected packages: everett, python-box, dulwich, configobj, comet_ml\n",
            "  Attempting uninstall: python-box\n",
            "    Found existing installation: python-box 7.3.2\n",
            "    Uninstalling python-box-7.3.2:\n",
            "      Successfully uninstalled python-box-7.3.2\n",
            "Successfully installed comet_ml-3.51.0 configobj-5.0.9 dulwich-0.24.1 everett-3.1.0 python-box-6.1.0\n",
            "Collecting torch==2.4.0\n",
            "  Downloading torch-2.4.0-cp312-cp312-manylinux1_x86_64.whl.metadata (26 kB)\n",
            "Collecting torchvision==0.19.0\n",
            "  Downloading torchvision-0.19.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.0 kB)\n",
            "Collecting torchaudio==2.4.0\n",
            "  Downloading torchaudio-2.4.0-cp312-cp312-manylinux1_x86_64.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (2025.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.4.0) (75.2.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.4.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.4.0)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.4.0)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.4.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.4.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.4.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch==2.4.0)\n",
            "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.4.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==3.0.0 (from torch==2.4.0)\n",
            "  Downloading triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.0) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.19.0) (11.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.4.0) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.4.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch==2.4.0) (1.3.0)\n",
            "Downloading torch-2.4.0-cp312-cp312-manylinux1_x86_64.whl (797.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.2/797.2 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.19.0-cp312-cp312-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m125.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchaudio-2.4.0-cp312-cp312-manylinux1_x86_64.whl (3.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m121.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m727.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.2/176.2 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.0.0-1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0+cu126\n",
            "    Uninstalling torch-2.8.0+cu126:\n",
            "      Successfully uninstalled torch-2.8.0+cu126\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.23.0+cu126\n",
            "    Uninstalling torchvision-0.23.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.23.0+cu126\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.8.0+cu126\n",
            "    Uninstalling torchaudio-2.8.0+cu126:\n",
            "      Successfully uninstalled torchaudio-2.8.0+cu126\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvtx-cu12-12.1.105 torch-2.4.0 torchaudio-2.4.0 torchvision-0.19.0 triton-3.0.0\n",
            "Collecting causal-conv1d==1.4.0\n",
            "  Downloading causal_conv1d-1.4.0.tar.gz (9.3 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from causal-conv1d==1.4.0) (2.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from causal-conv1d==1.4.0) (25.0)\n",
            "Collecting ninja (from causal-conv1d==1.4.0)\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (2025.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (75.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.12/dist-packages (from torch->causal-conv1d==1.4.0) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->causal-conv1d==1.4.0) (12.6.85)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->causal-conv1d==1.4.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch->causal-conv1d==1.4.0) (1.3.0)\n",
            "Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: causal-conv1d\n",
            "  Building wheel for causal-conv1d (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for causal-conv1d: filename=causal_conv1d-1.4.0-cp312-cp312-linux_x86_64.whl size=104884589 sha256=70c6d91d00c625d750b83c9c4bdd0bd395c61aff9baa8c0d58e0a33dabbe3b4e\n",
            "  Stored in directory: /root/.cache/pip/wheels/3a/bd/04/a4893fd5ad69a02f55b49f04dc1dbbd7c439332db7895f62ff\n",
            "Successfully built causal-conv1d\n",
            "Installing collected packages: ninja, causal-conv1d\n",
            "Successfully installed causal-conv1d-1.4.0 ninja-1.13.0\n",
            "Collecting mamba-ssm==2.2.2\n",
            "  Downloading mamba_ssm-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from mamba-ssm==2.2.2) (2.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from mamba-ssm==2.2.2) (25.0)\n",
            "Requirement already satisfied: ninja in /usr/local/lib/python3.12/dist-packages (from mamba-ssm==2.2.2) (1.13.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.12/dist-packages (from mamba-ssm==2.2.2) (0.8.1)\n",
            "Requirement already satisfied: triton in /usr/local/lib/python3.12/dist-packages (from mamba-ssm==2.2.2) (3.0.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from mamba-ssm==2.2.2) (4.55.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (2025.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (75.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.12/dist-packages (from torch->mamba-ssm==2.2.2) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.12/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->mamba-ssm==2.2.2) (12.6.85)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm==2.2.2) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm==2.2.2) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm==2.2.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm==2.2.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm==2.2.2) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm==2.2.2) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm==2.2.2) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers->mamba-ssm==2.2.2) (4.67.1)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers->mamba-ssm==2.2.2) (1.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->mamba-ssm==2.2.2) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->mamba-ssm==2.2.2) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->mamba-ssm==2.2.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->mamba-ssm==2.2.2) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers->mamba-ssm==2.2.2) (2025.8.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->torch->mamba-ssm==2.2.2) (1.3.0)\n",
            "Building wheels for collected packages: mamba-ssm\n",
            "  Building wheel for mamba-ssm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mamba-ssm: filename=mamba_ssm-2.2.2-cp312-cp312-linux_x86_64.whl size=324005633 sha256=f4cf06585ac28c783dbe6fe357c64218415af3665c3c06106be8f86dab69b2a8\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/b8/99/4112d82fe2a9458dd194c3ff54c43a14a8594c8f90cf16046f\n",
            "Successfully built mamba-ssm\n",
            "Installing collected packages: mamba-ssm\n",
            "Successfully installed mamba-ssm-2.2.2\n",
            "Collecting fvcore\n",
            "  Downloading fvcore-0.1.5.post20221221.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from fvcore) (2.0.2)\n",
            "Collecting yacs>=0.1.6 (from fvcore)\n",
            "  Downloading yacs-0.1.8-py3-none-any.whl.metadata (639 bytes)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from fvcore) (6.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from fvcore) (4.67.1)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.12/dist-packages (from fvcore) (3.1.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from fvcore) (11.3.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (from fvcore) (0.9.0)\n",
            "Collecting iopath>=0.1.7 (from fvcore)\n",
            "  Downloading iopath-0.1.10.tar.gz (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.12/dist-packages (from iopath>=0.1.7->fvcore) (4.14.1)\n",
            "Collecting portalocker (from iopath>=0.1.7->fvcore)\n",
            "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
            "Downloading yacs-0.1.8-py3-none-any.whl (14 kB)\n",
            "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
            "Building wheels for collected packages: fvcore, iopath\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fvcore: filename=fvcore-0.1.5.post20221221-py3-none-any.whl size=61397 sha256=af325e8fbc131ed4f275431c1a1c434892af7bc7ad53fdfb928b760b6026debc\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/9f/a5/e4f5b27454ccd4596bd8b62432c7d6b1ca9fa22aef9d70a16a\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for iopath: filename=iopath-0.1.10-py3-none-any.whl size=31527 sha256=4624875f4230ee74a922fd095adad756d1aa8950f19d03c1fcd84451d7331691\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/96/04/4f5f31ff812f684f69f40cb1634357812220aac58d4698048c\n",
            "Successfully built fvcore iopath\n",
            "Installing collected packages: yacs, portalocker, iopath, fvcore\n",
            "Successfully installed fvcore-0.1.5.post20221221 iopath-0.1.10 portalocker-3.2.0 yacs-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Pull Latest Repo\n",
        "from google.colab import userdata\n",
        "from pathlib import Path\n",
        "\n",
        "try:\n",
        "  gh_token = userdata.get('vad_clip_gh_token')\n",
        "except Exception:\n",
        "  gh_token = None\n",
        "\n",
        "REPO_NAME = \"vad_clip_colab_notebook\"\n",
        "REPO_PATH = Path(\"/content\") / REPO_NAME\n",
        "\n",
        "if gh_token:\n",
        "  GITHUB_URL = f\"https://{gh_token}@github.com/hammad-ali1/{REPO_NAME}.git\"\n",
        "else:\n",
        "  GITHUB_URL = f'https://github.com/hammad-ali1/{REPO_NAME}'\n",
        "\n",
        "!rm -rf {REPO_PATH}\n",
        "!git clone {GITHUB_URL}\n",
        "\n",
        "!cp -r {REPO_PATH}/* /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-3JvbCrKXHfc",
        "outputId": "6e574f8c-bd0a-4f2e-e765-845a84dbaab7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'vad_clip_colab_notebook'...\n",
            "remote: Enumerating objects: 177, done.\u001b[K\n",
            "remote: Counting objects: 100% (177/177), done.\u001b[K\n",
            "remote: Compressing objects: 100% (114/114), done.\u001b[K\n",
            "remote: Total 177 (delta 94), reused 123 (delta 61), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (177/177), 1.74 MiB | 13.09 MiB/s, done.\n",
            "Resolving deltas: 100% (94/94), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Import Modules\n",
        "import os\n",
        "from pathlib import Path\n",
        "from collections import OrderedDict\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "from enum import Enum\n",
        "\n",
        "import comet_ml\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import average_precision_score, roc_auc_score\n",
        "\n",
        "from clip import clip\n",
        "from models import CLIP_VMamba_S\n",
        "from utils.dataset import UCFDataset, XDDataset\n",
        "from utils.layers import GraphConvolution, DistanceAdj\n",
        "from utils.tools import get_batch_mask, get_prompt_text, get_batch_label\n",
        "from utils.ucf_detectionMAP import getDetectionMAP as dmAP"
      ],
      "metadata": {
        "id": "F_pOyYg7Ogdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61ec3a69-8416-46a8-a4f9-ff094dc3323e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
            "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
            "/usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:163: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd\n",
            "/usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/selective_scan_interface.py:239: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @custom_bwd\n",
            "/usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd\n",
            "/usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @custom_bwd\n",
            "/usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:25: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd\n",
            "/usr/local/lib/python3.12/dist-packages/mamba_ssm/distributed/tensor_parallel.py:61: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @custom_bwd\n",
            "/usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:757: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @custom_fwd\n",
            "/usr/local/lib/python3.12/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:835: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @custom_bwd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Datasets(Enum):\n",
        "  XD = 'XD'\n",
        "  UCF = 'UCF'\n",
        "\n",
        "CURRENT_DATASET = Datasets.XD"
      ],
      "metadata": {
        "id": "d1r1m31gpE5-"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_dataset(gdown_id, file_path, extract_to):\n",
        "    !gdown --id {gdown_id} -O {file_path}\n",
        "    !unzip -q {file_path} -d {extract_to}\n",
        "    !rm {file_path}"
      ],
      "metadata": {
        "id": "CXD5qsQDrs_Y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if CURRENT_DATASET == Datasets.UCF:\n",
        "  download_dataset('1DOkXHObwEGqmU3c9-J1gCIyVXiTMFfC5', '/content/UCFClipFeatures.zip', '/content')\n",
        "  TRAIN_DIR = Path('/content/UCFClipFeatures')\n",
        "  TEST_DIR = Path('/content/UCFClipFeatures')\n",
        "elif CURRENT_DATASET == Datasets.XD:\n",
        "  download_dataset('1bg2cyrsAaXjXM2MZv3j9x4gdqwl8Ntok', '/content/XDTrainClipFeatures.zip', '/content')\n",
        "  download_dataset('1fhZZWSfWRl_9xQXByFOx5PM3VUwjIfp5', '/content/XDTestClipFeatures.zip', '/content')\n",
        "  TRAIN_DIR = Path('/content/XDTrainClipFeatures')\n",
        "  TEST_DIR = Path('/content/XDTestClipFeatures')"
      ],
      "metadata": {
        "id": "aXPCB6SdOqzk",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UCFArgs:\n",
        "    seed = 234\n",
        "\n",
        "    embed_dim = 512\n",
        "    visual_length = 256\n",
        "    visual_width = 512\n",
        "    visual_head = 1\n",
        "    visual_layers = 2\n",
        "    attn_window = 8\n",
        "    prompt_prefix = 10\n",
        "    prompt_postfix = 10\n",
        "    classes_num = 14\n",
        "\n",
        "    max_epoch = 10\n",
        "    model_path = \"model_cur.pth\"\n",
        "    use_checkpoint = False\n",
        "    checkpoint_experiment_key = ''\n",
        "    checkpoint_file = \"best_checkpoint.pth\"\n",
        "    batch_size = 64\n",
        "    train_list = 'list/ucf_CLIP_rgb.csv'\n",
        "    test_list = 'list/ucf_CLIP_rgbtest.csv'\n",
        "    gt_path = 'list/gt_ucf.npy'\n",
        "    gt_segment_path = 'list/gt_segment_ucf.npy'\n",
        "    gt_label_path = 'list/gt_label_ucf.npy'\n",
        "\n",
        "    lr = 2e-5\n",
        "    scheduler_rate = 0.1\n",
        "    scheduler_milestones = [4, 8]\n",
        "\n",
        "\n",
        "\n",
        "class XDArgs:\n",
        "    seed = 234\n",
        "\n",
        "    embed_dim = 512\n",
        "    visual_length = 256\n",
        "    visual_width = 512\n",
        "    visual_head = 1\n",
        "    visual_layers = 1\n",
        "    attn_window = 64\n",
        "    prompt_prefix = 10\n",
        "    prompt_postfix = 10\n",
        "    classes_num = 7\n",
        "\n",
        "    max_epoch = 10\n",
        "    model_path = \"model_cur.pth\"\n",
        "    use_checkpoint = False\n",
        "    checkpoint_experiment_key = ''\n",
        "    checkpoint_file = \"best_checkpoint.pth\"\n",
        "    batch_size = 96\n",
        "    train_list = 'list/xd_CLIP_rgb.csv'\n",
        "    test_list = 'list/xd_CLIP_rgbtest.csv'\n",
        "    gt_path = 'list/gt.npy'\n",
        "    gt_segment_path = 'list/gt_segment.npy'\n",
        "    gt_label_path = 'list/gt_label.npy'\n",
        "\n",
        "    lr = 1e-5\n",
        "    scheduler_rate = 0.1\n",
        "    scheduler_milestones = [3, 6, 10]\n"
      ],
      "metadata": {
        "id": "0VPhYpQPbBSN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Args = XDArgs if CURRENT_DATASET == Datasets.XD else UCFArgs"
      ],
      "metadata": {
        "id": "RdPUn4BvuQxj"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "COMET_API_KEY = userdata.get('COMET_API_KEY')\n",
        "COMET_PROJECT_NAME = \"vad_clip_notebook\"\n",
        "COMET_WORKSPACE = 'hammad-ali'"
      ],
      "metadata": {
        "id": "Lv0xzsL-WtCv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_clip_model():\n",
        "  !curl -L -o VMamba_S_clip.pt \"https://huggingface.co/weiquan/mamba-clip/resolve/main/VMamba_S_clip.pt?download=true\"\n",
        "\n",
        "  mamba_clip_model = CLIP_VMamba_S()\n",
        "\n",
        "  ckpt_path = \"VMamba_S_clip.pt\"\n",
        "\n",
        "  ckpt = torch.load(ckpt_path, map_location='cpu', weights_only=False)\n",
        "  state_dict = OrderedDict()\n",
        "  for k, v in ckpt['state_dict'].items():\n",
        "      state_dict[k.replace('module.', '')] = v\n",
        "\n",
        "  mamba_clip_model.load_state_dict(state_dict, strict=True)\n",
        "\n",
        "  return mamba_clip_model"
      ],
      "metadata": {
        "id": "5HVPPoPb1tyq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_commet_asset(file_name):\n",
        "  comet_api = comet_ml.API(api_key=COMET_API_KEY)\n",
        "  checkpoint_experiment = comet_api.get_experiment(COMET_WORKSPACE, COMET_PROJECT_NAME, Args.checkpoint_experiment_key)\n",
        "  asset_link = [asset for asset in checkpoint_experiment.get_asset_list()\n",
        "                   if asset['fileName'] == file_name][0]['s3Link']\n",
        "  !curl -o {file_name} \"{asset_link}\""
      ],
      "metadata": {
        "id": "8Ui0g7gMXCSG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def update_lists(file_path, old_root, dataset_dir, limit_list=None):\n",
        "    df = pd.read_csv(file_path)\n",
        "\n",
        "    # Extract video ID (removing part suffix)\n",
        "    df['video_id'] = df['path'].apply(lambda x: x.rsplit('__', 1)[0])\n",
        "\n",
        "    # Keep only complete videos (with all 10 parts)\n",
        "    grouped = df.groupby('video_id')\n",
        "    complete_videos = grouped.filter(lambda x: len(x) == 10)\n",
        "\n",
        "    if limit_list is not None:\n",
        "        total_videos = limit_list // 10\n",
        "\n",
        "        # Create video-level metadata\n",
        "        video_meta = (\n",
        "            complete_videos.groupby('video_id')\n",
        "            .first()\n",
        "            .reset_index()[['video_id', 'label']]\n",
        "        )\n",
        "\n",
        "        # Separate Normal and Other labels\n",
        "        normal_videos = video_meta[video_meta['label'] == 'Normal']\n",
        "        other_videos = video_meta[video_meta['label'] != 'Normal']\n",
        "        other_labels = other_videos['label'].unique()\n",
        "\n",
        "        num_normal_videos = total_videos // 2\n",
        "        num_other_videos = total_videos - num_normal_videos\n",
        "        per_other_label = max(1, num_other_videos // len(other_labels))\n",
        "\n",
        "        # Sample Normal videos\n",
        "        selected_videos = normal_videos.sample(\n",
        "            n=min(num_normal_videos, len(normal_videos)), random_state=42\n",
        "        )\n",
        "\n",
        "        # Sample from other labels\n",
        "        for label in other_labels:\n",
        "            vids = other_videos[other_videos['label'] == label]\n",
        "            sampled = vids.sample(n=min(per_other_label, len(vids)), random_state=42)\n",
        "            selected_videos = pd.concat([selected_videos, sampled], ignore_index=True)\n",
        "\n",
        "        # Get all 10 parts of selected videos\n",
        "        final_df = complete_videos[complete_videos['video_id'].isin(selected_videos['video_id'])]\n",
        "\n",
        "        # Sort by video and clip number\n",
        "        final_df['part'] = final_df['path'].apply(lambda x: int(Path(x).stem.split('__')[-1]))\n",
        "        final_df = final_df.sort_values(by=['label', 'video_id', 'part']).drop(columns='part')\n",
        "    else:\n",
        "        final_df = df\n",
        "\n",
        "    # Fix paths relative to DATASET_DIR\n",
        "    final_df['path'] = final_df['path'].apply(lambda p: str(dataset_dir / Path(p).relative_to(old_root)))\n",
        "\n",
        "    # Save\n",
        "    final_df.drop(columns='video_id').to_csv(file_path, index=False)\n"
      ],
      "metadata": {
        "id": "57aXEliJT-Q0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if CURRENT_DATASET == Datasets.UCF:\n",
        "  old_train_root = Path('/content/drive/MyDrive/UCFClipFeatures')\n",
        "  old_test_root = Path('/content/drive/MyDrive/UCFClipFeatures')\n",
        "elif CURRENT_DATASET == Datasets.XD:\n",
        "  old_train_root = Path('/home/xbgydx/Desktop/XDTrainClipFeatures')\n",
        "  old_test_root = Path('/home/xbgydx/Desktop/XDTestClipFeatures')\n",
        "\n",
        "update_lists(Args.test_list, old_test_root, TEST_DIR)\n",
        "update_lists(Args.train_list, old_train_root, TRAIN_DIR, limit_list=None)"
      ],
      "metadata": {
        "id": "Gc_UEDSqVmDB"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mamba_clip_model = load_clip_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JCodBbMZ4Hs9",
        "outputId": "b12745d9-a7e3-4606-fb96-b83a8ea1c074"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  1319  100  1319    0     0   6800      0 --:--:-- --:--:-- --:--:--  6834\n",
            "100 1728M  100 1728M    0     0  68.5M      0  0:00:25  0:00:25 --:--:-- 77.3M\n",
            "=> merge config from /content/vmamba/configs/vssm1/vssm_small_224.yaml\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/vmamba/vmamba.py:262: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @torch.cuda.amp.custom_fwd\n",
            "/content/vmamba/vmamba.py:270: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @torch.cuda.amp.custom_bwd\n",
            "/content/vmamba/vmamba.py:285: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @torch.cuda.amp.custom_fwd\n",
            "/content/vmamba/vmamba.py:293: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @torch.cuda.amp.custom_bwd\n",
            "/content/vmamba/vmamba.py:306: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  @torch.cuda.amp.custom_fwd\n",
            "/content/vmamba/vmamba.py:314: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  @torch.cuda.amp.custom_bwd\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Model\n",
        "class LayerNorm(nn.LayerNorm):\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        orig_type = x.dtype\n",
        "        ret = super().forward(x.type(torch.float32))\n",
        "        return ret.type(orig_type)\n",
        "\n",
        "\n",
        "class QuickGELU(nn.Module):\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        return x * torch.sigmoid(1.702 * x)\n",
        "\n",
        "\n",
        "class ResidualAttentionBlock(nn.Module):\n",
        "    def __init__(self, d_model: int, n_head: int, attn_mask: torch.Tensor = None):\n",
        "        super().__init__()\n",
        "\n",
        "        self.attn = nn.MultiheadAttention(d_model, n_head)\n",
        "        self.ln_1 = LayerNorm(d_model)\n",
        "        self.mlp = nn.Sequential(OrderedDict([\n",
        "            (\"c_fc\", nn.Linear(d_model, d_model * 4)),\n",
        "            (\"gelu\", QuickGELU()),\n",
        "            (\"c_proj\", nn.Linear(d_model * 4, d_model))\n",
        "        ]))\n",
        "        self.ln_2 = LayerNorm(d_model)\n",
        "        self.attn_mask = attn_mask\n",
        "\n",
        "    def attention(self, x: torch.Tensor, padding_mask: torch.Tensor):\n",
        "        padding_mask = padding_mask.to(dtype=bool, device=x.device) if padding_mask is not None else None\n",
        "        self.attn_mask = self.attn_mask.to(device=x.device) if self.attn_mask is not None else None\n",
        "        return self.attn(x, x, x, need_weights=False, key_padding_mask=padding_mask, attn_mask=self.attn_mask)[0]\n",
        "\n",
        "    def forward(self, x):\n",
        "        x, padding_mask = x\n",
        "        x = x + self.attention(self.ln_1(x), padding_mask)\n",
        "        x = x + self.mlp(self.ln_2(x))\n",
        "        return (x, padding_mask)\n",
        "\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    def __init__(self, width: int, layers: int, heads: int, attn_mask: torch.Tensor = None):\n",
        "        super().__init__()\n",
        "        self.width = width\n",
        "        self.layers = layers\n",
        "        self.resblocks = nn.Sequential(*[ResidualAttentionBlock(width, heads, attn_mask) for _ in range(layers)])\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        return self.resblocks(x)\n",
        "\n",
        "\n",
        "class CLIPVAD(nn.Module):\n",
        "    def __init__(self,\n",
        "                 num_class: int,\n",
        "                 embed_dim: int,\n",
        "                 visual_length: int,\n",
        "                 visual_width: int,\n",
        "                 visual_head: int,\n",
        "                 visual_layers: int,\n",
        "                 attn_window: int,\n",
        "                 prompt_prefix: int,\n",
        "                 prompt_postfix: int,\n",
        "                 device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.num_class = num_class\n",
        "        self.visual_length = visual_length\n",
        "        self.visual_width = visual_width\n",
        "        self.embed_dim = embed_dim\n",
        "        self.attn_window = attn_window\n",
        "        self.prompt_prefix = prompt_prefix\n",
        "        self.prompt_postfix = prompt_postfix\n",
        "        self.device = device\n",
        "\n",
        "        self.temporal = Transformer(\n",
        "            width=visual_width,\n",
        "            layers=visual_layers,\n",
        "            heads=visual_head,\n",
        "            attn_mask=self.build_attention_mask(self.attn_window)\n",
        "        )\n",
        "\n",
        "        width = int(visual_width / 2)\n",
        "        self.gc1 = GraphConvolution(visual_width, width, residual=True)\n",
        "        self.gc2 = GraphConvolution(width, width, residual=True)\n",
        "        self.gc3 = GraphConvolution(visual_width, width, residual=True)\n",
        "        self.gc4 = GraphConvolution(width, width, residual=True)\n",
        "        self.disAdj = DistanceAdj()\n",
        "        self.linear = nn.Linear(visual_width, visual_width)\n",
        "        self.gelu = QuickGELU()\n",
        "\n",
        "        self.mlp1 = nn.Sequential(OrderedDict([\n",
        "            (\"c_fc\", nn.Linear(visual_width, visual_width * 4)),\n",
        "            (\"gelu\", QuickGELU()),\n",
        "            (\"c_proj\", nn.Linear(visual_width * 4, visual_width))\n",
        "        ]))\n",
        "        self.mlp2 = nn.Sequential(OrderedDict([\n",
        "            (\"c_fc\", nn.Linear(visual_width, visual_width * 4)),\n",
        "            (\"gelu\", QuickGELU()),\n",
        "            (\"c_proj\", nn.Linear(visual_width * 4, visual_width))\n",
        "        ]))\n",
        "        self.classifier = nn.Linear(visual_width, 1)\n",
        "\n",
        "        self.clipmodel = mamba_clip_model\n",
        "        for clip_param in self.clipmodel.parameters():\n",
        "            clip_param.requires_grad = False\n",
        "\n",
        "        self.frame_position_embeddings = nn.Embedding(visual_length, visual_width)\n",
        "        self.text_prompt_embeddings = nn.Embedding(77, self.embed_dim)\n",
        "\n",
        "        self.initialize_parameters()\n",
        "\n",
        "    def initialize_parameters(self):\n",
        "        nn.init.normal_(self.text_prompt_embeddings.weight, std=0.01)\n",
        "        nn.init.normal_(self.frame_position_embeddings.weight, std=0.01)\n",
        "\n",
        "    def build_attention_mask(self, attn_window):\n",
        "        # lazily create causal attention mask, with full attention between the vision tokens\n",
        "        # pytorch uses additive attention mask; fill with -inf\n",
        "        mask = torch.empty(self.visual_length, self.visual_length)\n",
        "        mask.fill_(float('-inf'))\n",
        "        for i in range(int(self.visual_length / attn_window)):\n",
        "            if (i + 1) * attn_window < self.visual_length:\n",
        "                mask[i * attn_window: (i + 1) * attn_window, i * attn_window: (i + 1) * attn_window] = 0\n",
        "            else:\n",
        "                mask[i * attn_window: self.visual_length, i * attn_window: self.visual_length] = 0\n",
        "\n",
        "        return mask\n",
        "\n",
        "    def adj4(self, x, seq_len):\n",
        "        soft = nn.Softmax(1)\n",
        "        x2 = x.matmul(x.permute(0, 2, 1)) # B*T*T\n",
        "        x_norm = torch.norm(x, p=2, dim=2, keepdim=True)  # B*T*1\n",
        "        x_norm_x = x_norm.matmul(x_norm.permute(0, 2, 1))\n",
        "        x2 = x2/(x_norm_x+1e-20)\n",
        "        output = torch.zeros_like(x2)\n",
        "        if seq_len is None:\n",
        "            for i in range(x.shape[0]):\n",
        "                tmp = x2[i]\n",
        "                adj2 = tmp\n",
        "                adj2 = F.threshold(adj2, 0.7, 0)\n",
        "                adj2 = soft(adj2)\n",
        "                output[i] = adj2\n",
        "        else:\n",
        "            for i in range(len(seq_len)):\n",
        "                tmp = x2[i, :seq_len[i], :seq_len[i]]\n",
        "                adj2 = tmp\n",
        "                adj2 = F.threshold(adj2, 0.7, 0)\n",
        "                adj2 = soft(adj2)\n",
        "                output[i, :seq_len[i], :seq_len[i]] = adj2\n",
        "\n",
        "        return output\n",
        "\n",
        "    def encode_video(self, images, padding_mask, lengths):\n",
        "        images = images.to(torch.float)\n",
        "        position_ids = torch.arange(self.visual_length, device=self.device)\n",
        "        position_ids = position_ids.unsqueeze(0).expand(images.shape[0], -1)\n",
        "        frame_position_embeddings = self.frame_position_embeddings(position_ids)\n",
        "        frame_position_embeddings = frame_position_embeddings.permute(1, 0, 2)\n",
        "        images = images.permute(1, 0, 2) + frame_position_embeddings\n",
        "\n",
        "        x, _ = self.temporal((images, None))\n",
        "        x = x.permute(1, 0, 2)\n",
        "\n",
        "        adj = self.adj4(x, lengths)\n",
        "        disadj = self.disAdj(x.shape[0], x.shape[1])\n",
        "        x1_h = self.gelu(self.gc1(x, adj))\n",
        "        x2_h = self.gelu(self.gc3(x, disadj))\n",
        "\n",
        "        x1 = self.gelu(self.gc2(x1_h, adj))\n",
        "        x2 = self.gelu(self.gc4(x2_h, disadj))\n",
        "\n",
        "        x = torch.cat((x1, x2), 2)\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def encode_textprompt(self, text):\n",
        "        word_tokens = clip.tokenize(text).to(self.device)\n",
        "        word_embedding = self.clipmodel.token_embedding(word_tokens)\n",
        "        text_embeddings = self.text_prompt_embeddings(torch.arange(77).to(self.device)).unsqueeze(0).repeat([len(text), 1, 1])\n",
        "        text_tokens = torch.zeros(len(text), 77).to(self.device)\n",
        "\n",
        "        for i in range(len(text)):\n",
        "            ind = torch.argmax(word_tokens[i], -1)\n",
        "            text_embeddings[i, 0] = word_embedding[i, 0]\n",
        "            text_embeddings[i, self.prompt_prefix + 1: self.prompt_prefix + ind] = word_embedding[i, 1: ind]\n",
        "            text_embeddings[i, self.prompt_prefix + ind + self.prompt_postfix] = word_embedding[i, ind]\n",
        "            text_tokens[i, self.prompt_prefix + ind + self.prompt_postfix] = word_tokens[i, ind]\n",
        "\n",
        "        text_features = self.clipmodel.encode_text(text_embeddings, text_tokens)\n",
        "\n",
        "        return text_features\n",
        "\n",
        "    def forward(self, visual, padding_mask, text, lengths):\n",
        "        visual_features = self.encode_video(visual, padding_mask, lengths)\n",
        "        logits1 = self.classifier(visual_features + self.mlp2(visual_features))\n",
        "\n",
        "        text_features_ori = self.encode_textprompt(text)\n",
        "\n",
        "        text_features = text_features_ori\n",
        "        logits_attn = logits1.permute(0, 2, 1)\n",
        "        visual_attn = logits_attn @ visual_features\n",
        "        visual_attn = visual_attn / visual_attn.norm(dim=-1, keepdim=True)\n",
        "        visual_attn = visual_attn.expand(visual_attn.shape[0], text_features_ori.shape[0], visual_attn.shape[2])\n",
        "        text_features = text_features_ori.unsqueeze(0)\n",
        "        text_features = text_features.expand(visual_attn.shape[0], text_features.shape[1], text_features.shape[2])\n",
        "        text_features = text_features + visual_attn\n",
        "        text_features = text_features + self.mlp1(text_features)\n",
        "\n",
        "        visual_features_norm = visual_features / visual_features.norm(dim=-1, keepdim=True)\n",
        "        text_features_norm = text_features / text_features.norm(dim=-1, keepdim=True)\n",
        "        text_features_norm = text_features_norm.permute(0, 2, 1)\n",
        "        logits2 = visual_features_norm @ text_features_norm.type(visual_features_norm.dtype) / 0.07\n",
        "\n",
        "        return text_features_ori, logits1, logits2, visual_features\n"
      ],
      "metadata": {
        "id": "2ODZ8AzzN3_M"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Test Function\n",
        "def test(model, testdataloader, maxlen, prompt_text, gt, gtsegments, gtlabels, device):\n",
        "\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    element_logits2_stack = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, item in enumerate(testdataloader):\n",
        "            visual = item[0].squeeze(0)\n",
        "            length = item[2]\n",
        "\n",
        "            length = int(length)\n",
        "            len_cur = length\n",
        "            if len_cur < maxlen:\n",
        "                visual = visual.unsqueeze(0)\n",
        "\n",
        "            visual = visual.to(device)\n",
        "\n",
        "            lengths = torch.zeros(int(length / maxlen) + 1)\n",
        "            for j in range(int(length / maxlen) + 1):\n",
        "                if j == 0 and length < maxlen:\n",
        "                    lengths[j] = length\n",
        "                elif j == 0 and length > maxlen:\n",
        "                    lengths[j] = maxlen\n",
        "                    length -= maxlen\n",
        "                elif length > maxlen:\n",
        "                    lengths[j] = maxlen\n",
        "                    length -= maxlen\n",
        "                else:\n",
        "                    lengths[j] = length\n",
        "            lengths = lengths.to(int)\n",
        "            padding_mask = get_batch_mask(lengths, maxlen).to(device)\n",
        "            _, logits1, logits2, _ = model(visual, padding_mask, prompt_text, lengths)\n",
        "            logits1 = logits1.reshape(logits1.shape[0] * logits1.shape[1], logits1.shape[2])\n",
        "            logits2 = logits2.reshape(logits2.shape[0] * logits2.shape[1], logits2.shape[2])\n",
        "            prob2 = (1 - logits2[0:len_cur].softmax(dim=-1)[:, 0].squeeze(-1))\n",
        "            prob1 = torch.sigmoid(logits1[0:len_cur].squeeze(-1))\n",
        "\n",
        "            if i == 0:\n",
        "                ap1 = prob1\n",
        "                ap2 = prob2\n",
        "                #ap3 = prob3\n",
        "            else:\n",
        "                ap1 = torch.cat([ap1, prob1], dim=0)\n",
        "                ap2 = torch.cat([ap2, prob2], dim=0)\n",
        "\n",
        "            element_logits2 = logits2[0:len_cur].softmax(dim=-1).detach().cpu().numpy()\n",
        "            element_logits2 = np.repeat(element_logits2, 16, 0)\n",
        "            element_logits2_stack.append(element_logits2)\n",
        "\n",
        "    ap1 = ap1.cpu().numpy()\n",
        "    ap2 = ap2.cpu().numpy()\n",
        "    ap1 = ap1.tolist()\n",
        "    ap2 = ap2.tolist()\n",
        "\n",
        "    ROC1 = roc_auc_score(gt, np.repeat(ap1, 16))\n",
        "    AP1 = average_precision_score(gt, np.repeat(ap1, 16))\n",
        "    ROC2 = roc_auc_score(gt, np.repeat(ap2, 16))\n",
        "    AP2 = average_precision_score(gt, np.repeat(ap2, 16))\n",
        "\n",
        "    print(\"AUC1: \", ROC1, \" AP1: \", AP1)\n",
        "    print(\"AUC2: \", ROC2, \" AP2:\", AP2)\n",
        "\n",
        "    if CURRENT_DATASET == Datasets.XD:\n",
        "      return ROC1, AP2, 0\n",
        "\n",
        "    dmap, iou = dmAP(element_logits2_stack, gtsegments, gtlabels, excludeNormal=False)\n",
        "    averageMAP = 0\n",
        "    for i in range(5):\n",
        "        print('mAP@{0:.1f} ={1:.2f}%'.format(iou[i], dmap[i]))\n",
        "        averageMAP += dmap[i]\n",
        "    averageMAP = averageMAP/(i+1)\n",
        "    print('average MAP: {:.2f}'.format(averageMAP))\n",
        "\n",
        "    return ROC1, AP1, averageMAP\n",
        "\n",
        "\n",
        "def run_test():\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    args = Args()\n",
        "\n",
        "    label_map = dict({'Normal': 'Normal', 'Abuse': 'Abuse', 'Arrest': 'Arrest', 'Arson': 'Arson', 'Assault': 'Assault', 'Burglary': 'Burglary', 'Explosion': 'Explosion', 'Fighting': 'Fighting', 'RoadAccidents': 'RoadAccidents', 'Robbery': 'Robbery', 'Shooting': 'Shooting', 'Shoplifting': 'Shoplifting', 'Stealing': 'Stealing', 'Vandalism': 'Vandalism'})\n",
        "\n",
        "    testdataset = UCFDataset(args.visual_length, args.test_list, True, label_map)\n",
        "    testdataloader = DataLoader(testdataset, batch_size=1, shuffle=False)\n",
        "\n",
        "    prompt_text = get_prompt_text(label_map)\n",
        "    gt = np.load(args.gt_path)\n",
        "    gtsegments = np.load(args.gt_segment_path, allow_pickle=True)\n",
        "    gtlabels = np.load(args.gt_label_path, allow_pickle=True)\n",
        "\n",
        "    model = CLIPVAD(args.classes_num, args.embed_dim, args.visual_length, args.visual_width, args.visual_head, args.visual_layers, args.attn_window, args.prompt_prefix, args.prompt_postfix, device)\n",
        "    model_param = torch.load(args.model_path)\n",
        "    model.load_state_dict(model_param)\n",
        "\n",
        "    test(model, testdataloader, args.visual_length, prompt_text, gt, gtsegments, gtlabels, device)"
      ],
      "metadata": {
        "id": "8LrMWNfSZ-RX"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TrainIterator:\n",
        "    def __init__(self, current_dataset, normal_loader=None, anomaly_loader=None, train_loader=None, device=\"cpu\", label_map=None, prompt_text=None):\n",
        "        self.current_dataset = current_dataset\n",
        "        self.normal_loader = normal_loader\n",
        "        self.anomaly_loader = anomaly_loader\n",
        "        self.train_loader = train_loader\n",
        "        self.device = device\n",
        "        self.label_map = label_map\n",
        "        self.prompt_text = prompt_text\n",
        "\n",
        "    def __iter__(self):\n",
        "        if self.current_dataset == Datasets.UCF:\n",
        "            normal_iter = iter(self.normal_loader)\n",
        "            anomaly_iter = iter(self.anomaly_loader)\n",
        "\n",
        "            for _ in range(min(len(self.normal_loader), len(self.anomaly_loader))):\n",
        "                normal_features, normal_label, normal_lengths = next(normal_iter)\n",
        "                anomaly_features, anomaly_label, anomaly_lengths = next(anomaly_iter)\n",
        "\n",
        "                # Concat features + lengths\n",
        "                visual_features = torch.cat([normal_features, anomaly_features], dim=0).to(self.device)\n",
        "                feat_lengths = torch.cat([normal_lengths, anomaly_lengths], dim=0).to(self.device)\n",
        "\n",
        "                # Merge labels\n",
        "                text_labels = list(normal_label) + list(anomaly_label)\n",
        "                text_labels = get_batch_label(text_labels, self.prompt_text, self.label_map).to(self.device)\n",
        "\n",
        "                yield visual_features, text_labels, feat_lengths\n",
        "\n",
        "        elif self.current_dataset == Datasets.XD:\n",
        "            for visual_features, text_labels, feat_lengths in self.train_loader:\n",
        "                visual_features = visual_features.to(self.device)\n",
        "                feat_lengths = feat_lengths.to(self.device)\n",
        "                text_labels = get_batch_label(text_labels, self.prompt_text, self.label_map).to(self.device)\n",
        "\n",
        "                yield visual_features, text_labels, feat_lengths\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown dataset {self.current_dataset}\")\n"
      ],
      "metadata": {
        "id": "whvZohMp2i5V"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Train Function\n",
        "\n",
        "class TripletLoss(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(TripletLoss, self).__init__()\n",
        "\n",
        "    def distance(self, x, y):\n",
        "        return torch.cdist(x, y, p=2)\n",
        "\n",
        "    def forward(self, feats, margin=100.0):\n",
        "        bs = feats.size(0)\n",
        "        n_feats = feats[:bs // 2]\n",
        "        a_feats = feats[bs // 2:]\n",
        "\n",
        "        # Shape: (N, N) and (N, A)\n",
        "        n_d = self.distance(n_feats, n_feats)\n",
        "        a_d = self.distance(n_feats, a_feats)\n",
        "\n",
        "        n_d_max, _ = torch.max(n_d, dim=0)         # shape: (N,)\n",
        "        a_d_min, _ = torch.min(a_d, dim=0)         # shape: (A,)\n",
        "\n",
        "        a_d_min = margin - a_d_min\n",
        "        a_d_min = torch.max(torch.zeros_like(a_d_min), a_d_min)  # element-wise clamp to >= 0\n",
        "\n",
        "        return torch.mean(n_d_max) + torch.mean(a_d_min)\n",
        "\n",
        "\n",
        "\n",
        "def CLASM(logits, labels, lengths, device):\n",
        "    instance_logits = torch.zeros(0).to(device)\n",
        "    labels = labels / torch.sum(labels, dim=1, keepdim=True)\n",
        "    labels = labels.to(device)\n",
        "\n",
        "    for i in range(logits.shape[0]):\n",
        "        tmp, _ = torch.topk(logits[i, 0:lengths[i]], k=int(lengths[i] / 16 + 1), largest=True, dim=0)\n",
        "        instance_logits = torch.cat([instance_logits, torch.mean(tmp, 0, keepdim=True)], dim=0)\n",
        "\n",
        "    milloss = -torch.mean(torch.sum(labels * F.log_softmax(instance_logits, dim=1), dim=1), dim=0)\n",
        "    return milloss\n",
        "\n",
        "def CLAS2(logits, labels, lengths, device):\n",
        "    instance_logits = torch.zeros(0).to(device)\n",
        "    labels = 1 - labels[:, 0].reshape(labels.shape[0])\n",
        "    labels = labels.to(device)\n",
        "    logits = torch.sigmoid(logits).reshape(logits.shape[0], logits.shape[1])\n",
        "\n",
        "    for i in range(logits.shape[0]):\n",
        "        tmp, _ = torch.topk(logits[i, 0:lengths[i]], k=int(lengths[i] / 16 + 1), largest=True)\n",
        "        tmp = torch.mean(tmp).view(1)\n",
        "        instance_logits = torch.cat([instance_logits, tmp], dim=0)\n",
        "\n",
        "    clsloss = F.binary_cross_entropy(instance_logits, labels)\n",
        "    return clsloss\n",
        "\n",
        "\n",
        "def train(model, train_iter, testloader, args, label_map, device, experiment):\n",
        "    model.to(device)\n",
        "    gt = np.load(args.gt_path)\n",
        "    gtsegments = np.load(args.gt_segment_path, allow_pickle=True)\n",
        "    gtlabels = np.load(args.gt_label_path, allow_pickle=True)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=args.lr)\n",
        "    scheduler = MultiStepLR(optimizer, args.scheduler_milestones, args.scheduler_rate)\n",
        "    triplet_loss_fn = TripletLoss().to(device)\n",
        "    prompt_text = get_prompt_text(label_map)\n",
        "    best_metric = 0\n",
        "    metric_to_optimize = 'ap' if CURRENT_DATASET == Datasets.XD else 'auc'\n",
        "    epoch = 0\n",
        "    global_step = 0\n",
        "\n",
        "    if args.use_checkpoint:\n",
        "        download_commet_asset(args.checkpoint_file)\n",
        "        checkpoint = torch.load(args.checkpoint_file, weights_only=False)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        epoch = checkpoint['epoch']\n",
        "        best_metric = checkpoint[metric_to_optimize]\n",
        "        print(\"checkpoint info:\")\n",
        "        print(\"epoch:\", epoch+1, f\" {metric_to_optimize}:\", best_metric)\n",
        "\n",
        "    for e in range(args.max_epoch):\n",
        "        curr_epoch = e + 1\n",
        "        experiment.log_current_epoch(curr_epoch)\n",
        "        model.train()\n",
        "        loss_total1 = 0\n",
        "        loss_total2 = 0\n",
        "\n",
        "        for i, (visual_features, text_labels, feat_lengths) in enumerate(train_iter):\n",
        "            step = i * Args.batch_size * 2\n",
        "            global_step += 1\n",
        "\n",
        "            text_features, logits1, logits2, visual_feats = model(visual_features, None, prompt_text, feat_lengths)\n",
        "\n",
        "            loss1 = CLAS2(logits1, text_labels, feat_lengths, device)\n",
        "            loss_total1 += loss1.item()\n",
        "\n",
        "            loss2 = CLASM(logits2, text_labels, feat_lengths, device)\n",
        "            loss_total2 += loss2.item()\n",
        "\n",
        "            triplet_loss_val = triplet_loss_fn(visual_feats)\n",
        "\n",
        "            loss3 = torch.zeros(1).to(device)\n",
        "            text_feature_normal = text_features[0] / text_features[0].norm(dim=-1, keepdim=True)\n",
        "            for j in range(1, text_features.shape[0]):\n",
        "                text_feature_abr = text_features[j] / text_features[j].norm(dim=-1, keepdim=True)\n",
        "                loss3 += torch.abs(text_feature_normal @ text_feature_abr)\n",
        "            loss3 = loss3 / 13 * 1e-1\n",
        "\n",
        "            loss = loss1 + loss2 + loss3 + 0.01 * triplet_loss_val\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            avg_loss1 = loss_total1 / (i + 1)\n",
        "            avg_loss2 = loss_total2 / (i + 1)\n",
        "            loss3_val = loss3.item()\n",
        "\n",
        "            # Comet logging (per step)\n",
        "            experiment.log_metric(\"loss1\", avg_loss1, step=global_step)\n",
        "            experiment.log_metric(\"loss2\", avg_loss2, step=global_step)\n",
        "            experiment.log_metric(\"loss3\", loss3_val, step=global_step)\n",
        "            experiment.log_metric(\"loss_triplet\", triplet_loss_val.item(), step=global_step)\n",
        "\n",
        "\n",
        "            if step % 1280 == 0 and step != 0:\n",
        "                print(f'epoch: {curr_epoch} | step: {step} | loss1: {avg_loss1:.4f} | loss2: {avg_loss2:.4f} | loss3: {loss3_val:.4f}')\n",
        "\n",
        "                # Evaluate\n",
        "                AUC, AP, averageMAP = test(model, testloader, args.visual_length, prompt_text, gt, gtsegments, gtlabels, device)\n",
        "                experiment.log_metric(\"AP\", AP, step=global_step)\n",
        "                experiment.log_metric(\"AUC\", AUC, step=global_step)\n",
        "                experiment.log_metric(\"Average_MAP\", averageMAP, step=global_step)\n",
        "\n",
        "                current_metric = AP if metric_to_optimize == 'ap' else AUC\n",
        "\n",
        "                if current_metric > best_metric:\n",
        "                    best_metric = current_metric\n",
        "                    experiment.log_metric(f\"Best_{metric_to_optimize.upper()}\", best_metric, step=global_step)\n",
        "\n",
        "                    checkpoint = {\n",
        "                        'epoch': curr_epoch,\n",
        "                        'model_state_dict': model.state_dict(),\n",
        "                        'optimizer_state_dict': optimizer.state_dict(),\n",
        "                         metric_to_optimize: best_metric\n",
        "                    }\n",
        "                    torch.save(checkpoint, args.checkpoint_file)\n",
        "\n",
        "                    # Log checkpoint to Comet\n",
        "                    experiment.log_asset(file_data=args.checkpoint_file, file_name=args.checkpoint_file, overwrite=True)\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        experiment.log_metric(\"epoch\", curr_epoch, step=global_step)\n",
        "\n",
        "        # Reload best checkpoint before next epoch\n",
        "        checkpoint = torch.load(args.checkpoint_file, weights_only=False)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "\n",
        "    # Save and log final model weights\n",
        "    checkpoint = torch.load(args.checkpoint_file, weights_only=False)\n",
        "    torch.save(checkpoint['model_state_dict'], args.model_path)\n",
        "    experiment.log_model(\"final_model\", args.model_path)\n",
        "\n",
        "\n",
        "def setup_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    #torch.backends.cudnn.deterministic = True\n",
        "\n",
        "def run_train(experiment):\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    args = Args()\n",
        "    setup_seed(args.seed)\n",
        "\n",
        "    if CURRENT_DATASET == Datasets.UCF:\n",
        "      label_map = dict({'Normal': 'normal', 'Abuse': 'abuse', 'Arrest': 'arrest', 'Arson': 'arson', 'Assault': 'assault', 'Burglary': 'burglary', 'Explosion': 'explosion', 'Fighting': 'fighting', 'RoadAccidents': 'roadAccidents', 'Robbery': 'robbery', 'Shooting': 'shooting', 'Shoplifting': 'shoplifting', 'Stealing': 'stealing', 'Vandalism': 'vandalism'})\n",
        "\n",
        "      normal_dataset = UCFDataset(args.visual_length, args.train_list, False, label_map, True)\n",
        "      normal_loader = DataLoader(normal_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "      anomaly_dataset = UCFDataset(args.visual_length, args.train_list, False, label_map, False)\n",
        "      anomaly_loader = DataLoader(anomaly_dataset, batch_size=args.batch_size, shuffle=True, drop_last=True)\n",
        "\n",
        "      test_dataset = UCFDataset(args.visual_length, args.test_list, True, label_map)\n",
        "      test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "    elif CURRENT_DATASET == Datasets.XD:\n",
        "      label_map = dict({'A': 'normal', 'B1': 'fighting', 'B2': 'shooting', 'B4': 'riot', 'B5': 'abuse', 'B6': 'car accident', 'G': 'explosion'})\n",
        "\n",
        "      train_dataset = XDDataset(args.visual_length, args.train_list, False, label_map)\n",
        "      train_loader = DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
        "\n",
        "      test_dataset = XDDataset(args.visual_length, args.test_list, True, label_map)\n",
        "      test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
        "\n",
        "\n",
        "    prompt_text = get_prompt_text(label_map)\n",
        "\n",
        "    train_iter = TrainIterator(\n",
        "        current_dataset=CURRENT_DATASET,\n",
        "        normal_loader=normal_loader if CURRENT_DATASET == Datasets.UCF else None,\n",
        "        anomaly_loader=anomaly_loader if CURRENT_DATASET == Datasets.UCF else None,\n",
        "        train_loader=train_loader if CURRENT_DATASET == Datasets.XD else None,\n",
        "        device=device,\n",
        "        label_map=label_map,\n",
        "        prompt_text=prompt_text,\n",
        "      )\n",
        "\n",
        "    model = CLIPVAD(args.classes_num, args.embed_dim, args.visual_length, args.visual_width, args.visual_head, args.visual_layers, args.attn_window, args.prompt_prefix, args.prompt_postfix, device)\n",
        "\n",
        "    train(model, train_iter, test_loader, args, label_map, device, experiment)\n",
        "\n"
      ],
      "metadata": {
        "id": "eyaLSBFMpdWk"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "experiment = comet_ml.Experiment(\n",
        "                  api_key=COMET_API_KEY,\n",
        "                  project_name=COMET_PROJECT_NAME)\n",
        "\n",
        "with experiment.train():\n",
        "  run_train(experiment)\n",
        "\n",
        "experiment.end()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBtt-FAfgY2A",
        "outputId": "9e67d005-d732-4876-9980-36e5c95ecc1f",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     name                  : flat_dessert_6344\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/hammad-ali/vad-clip-notebook/d5008c842b8a4e9d91e5b12ad7cd5e27\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     curr_epoch              : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss [3]          : (3.688724994659424, 4.881041526794434)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss1 [21]        : (0.6341090557121095, 1.2367403507232666)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss2 [21]        : (1.8316247633525304, 1.9099453687667847)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss3 [21]        : (0.044868580996990204, 0.04526694118976593)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss_triplet [21] : (140.26300048828125, 170.8482666015625)\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Others:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook_url : https://colab.research.google.com/notebook#fileId=https%3A%2F%2Fgithub.com%2Fhammad-ali1%2Fvad_clip_colab_notebook%2Fblob%2Fmain%2Fvad_clip_notebook.ipynb\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename            : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages  : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook            : 2\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code         : 1\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
            "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/hammad-ali/vad-clip-notebook/19e74186656846f0910346412d2d4735\n",
            "\n",
            "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Couldn't find a Git repository in '/content' nor in any parent directory. Set `COMET_GIT_DIRECTORY` if your Git Repository is elsewhere.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 | step: 3840 | loss1: 0.6341 | loss2: 1.8316 | loss3: 0.0449\n",
            "AUC1:  0.8118602589274566  AP1:  0.49492551791127704\n",
            "AUC2:  0.5911856816790272  AP2: 0.2828839954196463\n",
            "epoch: 1 | step: 7680 | loss1: 0.5219 | loss2: 1.7386 | loss3: 0.0438\n",
            "AUC1:  0.869501882858055  AP1:  0.6244935460977947\n",
            "AUC2:  0.6941002307608997  AP2: 0.3900166307098992\n",
            "epoch: 1 | step: 11520 | loss1: 0.4657 | loss2: 1.6432 | loss3: 0.0418\n",
            "AUC1:  0.8951022694269679  AP1:  0.6811501609584534\n",
            "AUC2:  0.789479305779756  AP2: 0.4919985574462133\n",
            "epoch: 1 | step: 15360 | loss1: 0.4274 | loss2: 1.5582 | loss3: 0.0390\n",
            "AUC1:  0.9099322663412064  AP1:  0.7147525447227142\n",
            "AUC2:  0.8539781070010186  AP2: 0.5301988082254321\n",
            "epoch: 1 | step: 19200 | loss1: 0.3943 | loss2: 1.4747 | loss3: 0.0358\n",
            "AUC1:  0.9166402212094118  AP1:  0.7297119004740841\n",
            "AUC2:  0.8678692455108434  AP2: 0.5386584836237396\n",
            "epoch: 1 | step: 23040 | loss1: 0.3686 | loss2: 1.3895 | loss3: 0.0326\n",
            "AUC1:  0.9213295630669529  AP1:  0.7394200197332585\n",
            "AUC2:  0.8812478650234625  AP2: 0.5532828409827827\n",
            "epoch: 1 | step: 26880 | loss1: 0.3474 | loss2: 1.3132 | loss3: 0.0294\n",
            "AUC1:  0.9307225125465837  AP1:  0.7849314552210597\n",
            "AUC2:  0.8959498092239842  AP2: 0.598348288215015\n",
            "epoch: 1 | step: 30720 | loss1: 0.3314 | loss2: 1.2429 | loss3: 0.0264\n",
            "AUC1:  0.9351083724404226  AP1:  0.7963055299725419\n",
            "AUC2:  0.9034654840304457  AP2: 0.6376340697699324\n",
            "epoch: 1 | step: 34560 | loss1: 0.3185 | loss2: 1.1824 | loss3: 0.0246\n",
            "AUC1:  0.9365298456215918  AP1:  0.7956295309101422\n",
            "AUC2:  0.9163998150353685  AP2: 0.7052125596104226\n",
            "epoch: 1 | step: 38400 | loss1: 0.3057 | loss2: 1.1258 | loss3: 0.0221\n",
            "AUC1:  0.9345271586254318  AP1:  0.7916680402121503\n",
            "AUC2:  0.920140124616357  AP2: 0.7358277543627276\n",
            "epoch: 1 | step: 42240 | loss1: 0.2935 | loss2: 1.0751 | loss3: 0.0207\n",
            "AUC1:  0.9340380767988348  AP1:  0.7876200487621243\n",
            "AUC2:  0.9259213791348457  AP2: 0.7561249335762756\n",
            "epoch: 1 | step: 46080 | loss1: 0.2846 | loss2: 1.0344 | loss3: 0.0196\n",
            "AUC1:  0.9359642237210342  AP1:  0.7925146617789125\n",
            "AUC2:  0.9274746201784076  AP2: 0.7656347039561915\n",
            "epoch: 1 | step: 49920 | loss1: 0.2760 | loss2: 0.9970 | loss3: 0.0178\n",
            "AUC1:  0.9335149651226187  AP1:  0.7836943971990916\n",
            "AUC2:  0.929507995210737  AP2: 0.7770551719013888\n",
            "epoch: 1 | step: 53760 | loss1: 0.2690 | loss2: 0.9633 | loss3: 0.0165\n",
            "AUC1:  0.938564220134446  AP1:  0.8020575659213245\n",
            "AUC2:  0.9370012277990246  AP2: 0.8065208986430763\n",
            "epoch: 1 | step: 57600 | loss1: 0.2619 | loss2: 0.9318 | loss3: 0.0158\n",
            "AUC1:  0.935197570292756  AP1:  0.7877517632555346\n",
            "AUC2:  0.9350283832306414  AP2: 0.8018216621970271\n",
            "epoch: 1 | step: 61440 | loss1: 0.2552 | loss2: 0.9029 | loss3: 0.0142\n",
            "AUC1:  0.9386544451500236  AP1:  0.8006026771061898\n",
            "AUC2:  0.9379155144311093  AP2: 0.8077774231146538\n",
            "epoch: 1 | step: 65280 | loss1: 0.2496 | loss2: 0.8775 | loss3: 0.0135\n",
            "AUC1:  0.9381527372168051  AP1:  0.7994720579840928\n",
            "AUC2:  0.9387656982927415  AP2: 0.8120308537413388\n",
            "epoch: 1 | step: 69120 | loss1: 0.2438 | loss2: 0.8536 | loss3: 0.0122\n",
            "AUC1:  0.9351374152953899  AP1:  0.7831131691784801\n",
            "AUC2:  0.9371113671559678  AP2: 0.8023304276958367\n",
            "epoch: 1 | step: 72960 | loss1: 0.2390 | loss2: 0.8311 | loss3: 0.0115\n",
            "AUC1:  0.9322899573795704  AP1:  0.7664593768043058\n",
            "AUC2:  0.9365412342078148  AP2: 0.7988187844317127\n"
          ]
        }
      ]
    }
  ]
}